version: "3.9"

services:
  ollama:
    image: ollama/ollama:latest
    container_name: career-coach-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 20
      start_period: 120s
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        limits:
          memory: 8G

  ollama-pull:
    image: ollama/ollama:latest
    container_name: career-coach-ollama-pull
    depends_on:
      ollama:
        condition: service_healthy
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        set -e
        echo "=========================================="
        echo "Starting Mistral Model Download"
        echo "=========================================="
        echo ""
        echo "Waiting for Ollama to be fully ready..."
        sleep 20
        
        echo ""
        echo "Checking if model already exists..."
        if ollama list | grep -q mistral; then
          echo "✓ Mistral model already downloaded!"
          ollama list
          exit 0
        fi
        
        echo ""
        echo "Downloading Mistral model..."
        echo "This will take 10-15 minutes depending on your connection"
        echo ""
        
        # Try to pull mistral with timeout
        timeout 1800 ollama pull mistral || {
          echo ""
          echo "⚠ Mistral download failed or timed out"
          echo "Trying TinyLlama as fallback..."
          ollama pull tinyllama
          echo ""
          echo "✓ TinyLlama downloaded successfully"
          echo "⚠ NOTE: Using smaller model (lower quality)"
          ollama list
          exit 0
        }
        
        echo ""
        echo "✓ Mistral model downloaded successfully!"
        echo ""
        echo "Available models:"
        ollama list
        echo ""
        echo "=========================================="
        echo "Model download complete!"
        echo "=========================================="
    volumes:
      - ollama_data:/root/.ollama
    restart: "no"

  app:
    build: .
    container_name: career-coach-app
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=mistral
      - PORT=7860
      - GRADIO_SERVER_NAME=0.0.0.0
    depends_on:
      ollama:
        condition: service_healthy
      ollama-pull:
        condition: service_completed_successfully
    ports:
      - "7860:7860"
    volumes:
      - ./Data:/app/Data
      - ./temp:/app/temp

volumes:
  ollama_data: